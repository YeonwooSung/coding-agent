# Global LLM configuration
[llm] # Amazon Bedrock
api_type = "aws"                                       # Required
model = "us.anthropic.claude-sonnet-4-20250514-v1:0" # Bedrock supported modelID
base_url = "bedrock-runtime.us-east-1.amazonaws.com"   # Not used now
max_tokens = 8192
temperature = 1.0
api_key = "bear"                                       # Required but not used for Bedrock

# Optional configuration for specific LLM models
[llm.vision] # Amazon Bedrock
api_type = "aws"                                       # Required
model = "us.anthropic.claude-sonnet-4-20250514-v1:0" # Bedrock supported modelID
base_url = "bedrock-runtime.us-east-1.amazonaws.com"   # Not used now
max_tokens = 8192
temperature = 1.0
api_key = "bear"                                       # Required but not used for Bedrock

# MCP (Model Context Protocol) configuration
[mcp]
server_reference = "app.mcp.server" # default server module reference
